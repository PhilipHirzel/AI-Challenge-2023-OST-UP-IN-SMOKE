{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Override Driving\n",
    "\n",
    "Für Pre- oder Postprocessing (also alles was vor oder nach dem Ausführen des Modelles kommt) kann die Datei `override_driving.py` angepasst werden und zusammen mit dem Modell im Auto hochgeladen werden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anwendungsbeispiele\n",
    "\n",
    "Als Idee\n",
    "\n",
    "- Eine Farbfilter einbauen (z.B. nur blauer Farbkanal geht ins Model)\n",
    "    - Natürlich muss dieser Filter auch beim Training eingebaut werden\n",
    "- Steering oder Throttle nachbearbeiten (ungültige oder extreme Werte abfangen)\n",
    "  - Z.B. Throttle muss immer >0.0 sein\n",
    "- Throttle auf einen fixen Wert setzten und nur Steering trainieren*\n",
    "- Eine Serie von Bilder ins Model geben anstatt nur ein Bild (anspruchsvoll)\n",
    "- ...\n",
    "\n",
    "*bei der Challenge wird getestet, wie gut das Modell die Bahn abfährt und wie schnell es dabei ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhalt und Funktionsweise von `override_driving.py`\n",
    "\n",
    "Auf dem Auto wird für jedes Kamerabild die Methode `predict_throttle_speed(image)` aufgerufen, welche als Rückgabewert `return throttle, steering` liefern muss. Alles andere kann grundsätzlich angepasst werden.\n",
    "\n",
    "Inhalt vom original `override_driving.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import onnxruntime as ort\n",
    "from torchvision import transforms\n",
    "\n",
    "# HINT Diese Libraries sind auf dem Raspberry Pi installiert und dürfen daher verwendet werden\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import cv2\n",
    "# from PIL import Image\n",
    "# Alle Python-Standardlibs können auch verwendet werden\n",
    "\n",
    "convert_tensor = transforms.ToTensor()\n",
    "\n",
    "path = Path(os.path.dirname(os.path.realpath(__file__)))\n",
    "\n",
    "model = path / 'self_driving_model.onnx' # HINT Modelname so ändern wie dein Modell heisst\n",
    "ORT_SESSION = ort.InferenceSession(str(model), providers=['CPUExecutionProvider'])\n",
    "idx = 0\n",
    "\n",
    "def predict_next_input(image):\n",
    "    global ORT_SESSION\n",
    "    tensor_img = convert_tensor(image).unsqueeze(0).numpy()\n",
    "    result = ORT_SESSION.run(None, {'image': tensor_img})\n",
    "    steering_data = float(result[0][0][1])\n",
    "    throttle_data = float(result[0][0][0])\n",
    "    return throttle_data, steering_data\n",
    "\n",
    "\n",
    "def predict_throttle_speed(image): # HINT Methodenname&Parameter nicht verändern. Diese wird vom Raspberry Pi aufgerufen\n",
    "    throttle, steering = predict_next_input(image)\n",
    "    return throttle, steering # HINT Rückgabe muss genau so sein\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Override Driving Vorlage mit Blaufilter\n",
    "\n",
    "zu verwenden mit `06d_Fahrmodell_Training_mit_Blaufilter.ipynb`. Denke daran, die gleichen Werte bei den Filter zu setzten wie beim Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import onnxruntime as ort\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "convert_tensor = transforms.ToTensor()\n",
    "\n",
    "path = Path(os.path.dirname(os.path.realpath(__file__)))\n",
    "\n",
    "model = path / 'self_driving_model_blaufilter.onnx' # HINT Modelname so ändern wie dein Modell heisst\n",
    "ORT_SESSION = ort.InferenceSession(str(model), providers=['CPUExecutionProvider'])\n",
    "idx = 0\n",
    "\n",
    "\n",
    "def predict_next_input(image):\n",
    "    global ORT_SESSION\n",
    "    image = filter_image(image)\n",
    "    tensor_img = convert_tensor(image).unsqueeze(0).numpy()\n",
    "    result = ORT_SESSION.run(None, {'image': tensor_img})\n",
    "    steering_data = result[0][0][1]\n",
    "    throttle_data = result[0][0][0]\n",
    "    return throttle_data, steering_data\n",
    "\n",
    "\n",
    "def predict_throttle_speed(image): # HINT Methodenname&Parameter nicht verändern. Diese wird vom Raspberry Pi aufgerufen\n",
    "    throttle, steering = predict_next_input(image)\n",
    "    return throttle, steering # HINT Rückgabe muss genau so sein\n",
    "\n",
    "\n",
    "\n",
    "def filter_image(pil_image):\n",
    "\n",
    "    # Bild als array laden und in korrektes Format bringen\n",
    "    image_array = np.array(pil_image)\n",
    "    image_array *= 255\n",
    "    image_array = 255 - cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Color Filter\n",
    "    lower1 = np.array([0, 75, 115]) # <- Werte können angepasst werden\n",
    "    upper1 = np.array([115, 205, 255]) # <- Werte können angepasst werden\n",
    "    color_filtered = cv2.inRange(image_array, lower1, upper1)\n",
    "\n",
    "    # Kleinere Pixelbereiche entfernen\n",
    "    kernel = np.ones((2, 2), np.uint8) # <- Werte können angepasst werden, z.B. (4,4)\n",
    "    dilated_mask = cv2.erode(color_filtered, kernel, iterations=1)\n",
    "\n",
    "    # Oberer Bildbereich abschneiden\n",
    "    dilated_mask[:70, :] = 0.0 # <- Wert kann angepasst werden, z.B. [:50, :]\n",
    "\n",
    "    # Debug-Ausgaben (auskommentieren, wenn ihr die Bilder im Model-Zip speichern wollt)\n",
    "    # Die Bilder landen im .zip und ihr könnt im Webinterface einfach das zip heruterladen\n",
    "    # bgr_image = cv2.cvtColor(dilated_mask, cv2.COLOR_GRAY2BGR)\n",
    "    # cv2.imwrite(str(path / f\"output_image_{idx}_maks.png\"), bgr_image)\n",
    "    # cv2.imwrite(str(path / f\"output_image_{idx}_color.png\"), image_array)\n",
    "    # np.save(str(path / f\"./image_array_{idx}.np\"),image_array)\n",
    "\n",
    "    return dilated_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenes `override_driving.py` auf Auto laden\n",
    "\n",
    "Das Auto akzeptiert beim hochladen des Models entweder ein einfach `*.onnx` Model oder, wenn ihr `override_driving.py` benützten wollt, ein `*.zip`, welches das `override_driving.py` sowie ein Modell enthält.\n",
    "\n",
    "**Beispiel:**\n",
    "- `model_v0.zip` enthält:\n",
    "  - `override_driving.py` (muss genau so heissen)\n",
    "  - `self_driving_model.py` (muss so heissen, wie im `override_driving.py` angegeben)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
