{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0eT8r5sjPVZ"
      },
      "source": [
        "# Training Bilderkennung Stoppschild\n",
        "\n",
        "In diesem Notebook werden wir unser erstes Training mit den gelabelten Bildern der Stoppschild-Erkennung machen.\n",
        "\n",
        "Das Notebook ist sehr √§hnlich aufgebaut wie das von letzter Woche ([02c_Bilderkennung_mit_FastAI](../02_Homework/02c_Bilderkennung_mit_FastAI.ipynb)). Schaue, dass du das Notebook verstanden hast, da hier nicht mehr alles im Detail erkl√§rt wird."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNCrUZ8cO28a"
      },
      "outputs": [],
      "source": [
        "from fastai.data.all import *\n",
        "from fastai.vision.all import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oddeaf1hSpT6",
        "outputId": "b8f3bf51-a080-41d5-a4e7-b412c8ff378b"
      },
      "outputs": [],
      "source": [
        "# Sicherstellen, dass die GPU ben√ºtzt wird, sonst geht das Training viel zu lange\n",
        "setup_cuda()\n",
        "\n",
        "# Als Ausgabe sollte folgendes stehen: Device selected: cuda:0\n",
        "device = default_device()\n",
        "print(f\"Device selected: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxTwmiKlQNwb"
      },
      "source": [
        "## Daten sammeln\n",
        "\n",
        "Wir haben die Daten schon im vorhergehenden Notebook gesammelt und gelabelt. Wenn nicht, hole das nach.\n",
        "\n",
        "Danach kopiere die Daten auf dein Google Drive und verbinde es mit Colab (so wie du es letzte Woche gemacht hast)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rovIjyWcQVkh",
        "outputId": "9df2ef6c-c681-48b0-ba37-aef59fa7c878"
      },
      "outputs": [],
      "source": [
        "# Mit deinem Google Drive verbinden\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQSdLJBn7jkW",
        "outputId": "bf2be127-de06-458a-9628-779cdc45c3fc"
      },
      "outputs": [],
      "source": [
        "# Pfad mit dem Ordner, wo die Bilder liegen. √Ñndere den Pfad, falls die Dateien bei dir an einem anderen Ort liegen.\n",
        "image_directory_path = Path('/content/drive/MyDrive/AI-Challenge/daten/stoppschild-erkennung/train')\n",
        "\n",
        "# Sollte der Pfad nicht existieren, wird hier eine Fehlermeldung ausgegeben\n",
        "if not image_directory_path.exists():\n",
        "    raise Exception(f\"Fehlerüõë Der Pfad {image_directory_path} existiert nicht\")\n",
        "else:\n",
        "    print(f\"Alles gutüëç der Pfad {image_directory_path} wurde gefunden\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "o2CW8MImQNwb",
        "outputId": "83f19f80-e3b2-4e04-b8ad-0a4140e65a84"
      },
      "outputs": [],
      "source": [
        "# Wir sehen, ob alle Bilder gefunden werden, die richtige Gr√∂sse haben und schauen uns eins an\n",
        "\n",
        "# alle Bildpfade laden\n",
        "image_paths = get_image_files(image_directory_path)\n",
        "print(f\"Es wurden {len(image_paths)} Bilder gefunden\")\n",
        "\n",
        "# den ersten Pfad ausw√§hlen und ausgeben (wenn du einen anderen willst, √§ndere den Index)\n",
        "some_image_path = image_paths[0]\n",
        "print(some_image_path)\n",
        "\n",
        "# Wir k√∂nnen das Label bestimmen je nach dem in welchem Ordner es liegt\n",
        "print(f\"Das Bild {some_image_path.name} hat das Label: {some_image_path.parent.name}\")\n",
        "\n",
        "# Bild laden und anzeigen\n",
        "img = PILImage.create(some_image_path)\n",
        "img.show()\n",
        "\n",
        "# Pr√ºfe die Gr√∂sse, diese sollte 160x120 betragen\n",
        "if not img.size == (160,120):\n",
        "    raise Exception(f\"Fehlerüõë Bild hat die falsche Gr√∂sse (ist {img.size})\")\n",
        "else:\n",
        "    print(f\"Alles gutüëç Bild hat die korrekte Gr√∂sse von {img.size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfboSfB0ooKu"
      },
      "source": [
        "## Daten aufbereiten\n",
        "\n",
        "Auch hier m√ºssen wir alle Bilder in einen `ImageDataloaders` laden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkX0BrKh-p1c"
      },
      "outputs": [],
      "source": [
        "# Das Label ist der Ordnername in dem das Bild liegt\n",
        "def label_func(filePath):\n",
        "  return filePath.parent.name\n",
        "\n",
        "dls = ImageDataLoaders.from_path_func(\n",
        "    image_directory_path,\n",
        "    get_image_files(image_directory_path),\n",
        "    valid_pct=0.2, # 20% der Daten f√ºr die Validierung verwenden\n",
        "    bs=64, # Batch-Size sollte immer eine 2-er Potenz sein (8, 16, 32, 64, 128,...)\n",
        "    shuffle=True, # Mischen macht Sinn, damit die Batches Stoppschilder und keine Stoppschilder enthalten\n",
        "    label_func=label_func,\n",
        "    device=default_device() # ben√ºtze die GPU, falls vorhanden\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "8YDqY96OQNwc",
        "outputId": "f2035955-8c34-48c9-cf33-53282558cf7a"
      },
      "outputs": [],
      "source": [
        "# Wir k√∂nnen uns ein Batch anzeigen lassen (es werden nur die ersten 9 Bilder angezeigt)\n",
        "dls.show_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldAhwoEb5Ap7",
        "outputId": "a26b2e02-bd67-4b99-eca2-6b6bba494ab3"
      },
      "outputs": [],
      "source": [
        "# Wir sehen uns mal den Shape an\n",
        "batch_data, batch_labels = dls.one_batch()\n",
        "batch_data.shape\n",
        "\n",
        "# Stelle dir auch hier die Frage, was bedeuten diese Zahlen?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsZ456NJfwfR",
        "outputId": "1f656436-cdef-48e6-f9e2-4f435cfd7334"
      },
      "outputs": [],
      "source": [
        "# Wir k√∂nnen uns das Vocabulary ansehen. Also welche Ausgabe welches Label bedeuten\n",
        "dls.vocab\n",
        "\n",
        "# Somit also 0=noStopSigns / 1=stopSigns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCNLjuStQNwd"
      },
      "source": [
        "## Model definieren & trainieren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLAIzcNvjWxv"
      },
      "source": [
        "### Model definieren\n",
        "\n",
        "Anders als letzte Woche, definieren wir nun unser Modell selbst. Dazu ben√ºtzen wir die Pytorch-Library (`torch`), auf welche FastAI aufbaut. Mit `Sequential` geben wir an, dass die enthaltenen Layer alle nacheinander kommen sollen. Was die einzelnen Layer genau machen, ist im Theorie-Notebook dieser Woche beschrieben.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9RXHKeOQNwd"
      },
      "outputs": [],
      "source": [
        "# Wir definieren unsere eigene Architektur unseres neuronalen Netzwerks\n",
        "model = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3,16,3),\n",
        "            torch.nn.BatchNorm2d(16),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout2d(p=0.2),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            torch.nn.Conv2d(16,32,3),\n",
        "            torch.nn.BatchNorm2d(32),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout2d(p=0.2),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            torch.nn.Conv2d(32,64,3),\n",
        "            torch.nn.BatchNorm2d(64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout2d(p=0.2),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            torch.nn.Conv2d(64,128,3),\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout2d(p=0.2),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            torch.nn.Conv2d(128,256,3),\n",
        "            torch.nn.BatchNorm2d(256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout2d(p=0.2),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            torch.nn.Flatten(1,-1),\n",
        "            torch.nn.Linear(768,256),\n",
        "            torch.nn.BatchNorm1d(256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.5),\n",
        "\n",
        "            torch.nn.Linear(256,64),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.5),\n",
        "\n",
        "            torch.nn.Linear(64,32),\n",
        "            torch.nn.BatchNorm1d(32),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.5),\n",
        "\n",
        "            torch.nn.Linear(32,1),\n",
        "            torch.nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "# Modell auf der GPU laufen lassen (falls vorhanden)\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQ2O8_CR7Bx"
      },
      "source": [
        "### Learner erstellen\n",
        "\n",
        "Wir definieren den `Learner` direkt und geben ihm alle ben√∂tigten Sachen mit, darunter unser Modell, welches wir erstellt haben\n",
        "\n",
        "Als Metric verwenden wir hier anstatt der Genauigkeit (Accuracy) den `F1Score()`. Der F1-Score eignet sich in unserem Fall gut, da wir ein grosses Ungleichgewicht in den Daten haben. Das bedeutet, wir haben viel mehr Fotos ohne Stoppschilder als mit. Das Problem mit Accuracy und Ungleichgewicht ist, wenn das Modell stur behaupten w√ºrde, dass jedes Bild kein Stoppschild ist, so h√§tte es in den allermeisten F√§llen recht und die Accuracy w√§re hoch, obwohl es kein einziges Stoppschild erkannt h√§tte.\n",
        "\n",
        "Die F1-Score hingegen kombiniert die Pr√§zision (Precision) mit der Sensitivit√§t (Recall) und ist so f√ºr unseren Fall viel aussagekr√§ftiger. Falls du dich tiefer damit befassen willst, findest du hier eine ausf√ºhrlich aber gut verst√§ndliche Erkl√§rung:\n",
        "- [www.python-kurs.eu/metriken.php](https://www.python-kurs.eu/metriken.php)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06G_bAMKoENO"
      },
      "outputs": [],
      "source": [
        "# Wir definieren den F1-Score. Da unser Modell die Probability ausgibt, m√ºssen wir diese noch runden:\n",
        "f1score_raw = F1Score()\n",
        "def f1score(true, pred, *args, **kwargs):\n",
        "  true = true.round().to(torch.int)\n",
        "  pred = pred.round().to(torch.int)\n",
        "  return f1score_raw(true, pred)\n",
        "\n",
        "\n",
        "# Wir definieren den Learner mit unserem Modell\n",
        "learn = Learner(\n",
        "    dls=dls, # Unsere Daten\n",
        "    model=model, # Unser Modell\n",
        "    loss_func=BCELossFlat(), # Als Loss-Funktion eignet sich BCELossFlat\n",
        "    metrics=f1score, # Unsere F1-Score\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o_hCMcMyQNwd",
        "outputId": "d9cf5c53-593f-4bf1-8ac0-4a55c85dc521"
      },
      "outputs": [],
      "source": [
        "# Modell Architektur anschauen\n",
        "learn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px-Gh9lWQNwd"
      },
      "source": [
        "### Beste Lernrate finden\n",
        "\n",
        "Wer letzte Woche das Notebook gut durchgearbeitet hat, der weiss noch, dass FastAI eine Funktion zur Verf√ºgung stellt, mit der die ideale Lernrate ermittelt werden kann. Diese f√ºhrt Probetrainings mit verschiedenen Lernraten durch. Die Kurve beginnt zuerst zu sinken und erreicht den idealen Wert etwa bevor sie wieder stark zu steigen beginnt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "g0vwwjQ-QlXk",
        "outputId": "cb003d40-9787-4f9c-e2eb-e605c4a38df2"
      },
      "outputs": [],
      "source": [
        "suggested_lr = learn.lr_find().valley\n",
        "\n",
        "print(f\"Die empfohlene Lernrate ist {suggested_lr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cdz80lSjnOA"
      },
      "source": [
        "### Training\n",
        "\n",
        "F√ºr Training verwenden wir anstatt der `.fit()` Funktion die `.fit_one_cycle()`. Diese ist sehr √§hnlich, hilft aber nochmals, das Training zu beschleunigen (respektive die Anzahl der ben√∂tigten Epochen zu verringern). Das funktioniert, da sie gem√§ss der 1Cycle-Policy die Lernrate ver√§ndert. Die Praxis hat gezeigt, dass dies besser funktioniert als mit einer konstanten Lernrate wie beim normalen `.fit()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "-WOIYVIgcSH9",
        "outputId": "9a9add0c-89ee-4ba7-8a2b-3550534e7f3a"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# Anzahl Epochen, die wir lernen wollen. Passe den Wert an wenn du willst\n",
        "epochs = 15\n",
        "\n",
        "# Beginne mit dem Lernen\n",
        "learn.fit_one_cycle(\n",
        "    n_epoch=epochs,\n",
        "    lr_max=suggested_lr, # die vorher ermittelte Lernrate\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "CREssgzTrfNo",
        "outputId": "7c90061a-ff39-4fc1-e00a-f161d90fe576"
      },
      "outputs": [],
      "source": [
        "# Nach dem Training k√∂nnen wir die Fehlerkurve anschauen und ermitteln, ob es zu einem Over/Underfitting gekommen ist.\n",
        "learn.recorder.plot_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqiFFd-We6ZV"
      },
      "source": [
        "## Validierung\n",
        "\n",
        "Wir k√∂nnen aus der Lernkurve schon einiges ablesen, nun wollen wir uns noch einige andere Dinge ansehen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZugDsJTeJUc"
      },
      "outputs": [],
      "source": [
        "# (Diese Zeile ist n√∂tig, damit show_results korrekt funktioniert. Ihr m√ºsst die Details nicht verstehen)\n",
        "import types\n",
        "def show_results(self, ds_idx=1, dl=None, max_n=9, shuffle=True, **kwargs):\n",
        "    if dl is None: dl = self.dls[ds_idx].new(shuffle=shuffle)\n",
        "    b = dl.one_batch()\n",
        "    _,_,preds = self.get_preds(dl=[b], with_decoded=True, act=lambda p: p.round().to(torch.int).squeeze()) # fix with act=\n",
        "    dl.show_results(b, preds, max_n=max_n, **kwargs)\n",
        "\n",
        "learn.show_results =  types.MethodType(show_results, learn) # batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "YL3yX8wKQNwe",
        "outputId": "6e994b67-bc14-4482-fdbd-fe67260010e8"
      },
      "outputs": [],
      "source": [
        "# Ein paar (zuf√§llige) Vorhersagen aus dem Validationset machen. Du kannst diese Zeile also mehrmals ausf√ºhren und bekommst immer andere Beispiele.\n",
        "learn.show_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "-aYJdzSZgxGT",
        "outputId": "5a0b9d4c-d684-41fb-f76e-446dd5362e91"
      },
      "outputs": [],
      "source": [
        "# Ein einzelnes Bild vorhersagen\n",
        "\n",
        "img = PILImage.create(some_image_path)\n",
        "img.show()\n",
        "\n",
        "label, probability, _ = learn.predict(img)\n",
        "print(f\"Das ist ein {label} mit einer Wahrscheinlichkeit von {probability.item():.0%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "Rz_cj3JWN8qd",
        "outputId": "d8ce0be0-df5e-4aa3-833e-b2aad6bed80d"
      },
      "outputs": [],
      "source": [
        "# Und wir k√∂nnen auch den Interpreter ben√ºtzten\n",
        "interp = ClassificationInterpretation.from_learner(learn, act=lambda p: p.round().to(torch.int).squeeze())\n",
        "interp.plot_top_losses(9, figsize=(15,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "HC63dljupvmn",
        "outputId": "6e9df818-fa96-40cc-a9f4-515db7d31097"
      },
      "outputs": [],
      "source": [
        "# Wir k√∂nnen uns auch die Confusion Matrix anzeigen lassen.\n",
        "# Wie diese genau funktioniert und was du dort herauslesen kannst findest du hier: https://www.python-kurs.eu/metriken.php\n",
        "\n",
        "interp.plot_confusion_matrix(figsize=(5,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "bejrAS3nQNwf",
        "outputId": "6a578efb-d508-42d0-ac6a-128cddebbff5"
      },
      "outputs": [],
      "source": [
        "# Wir k√∂nnen uns anstatt der absoluten Nummer auch die Genauigkeit in Prozent anzeigen lassen:\n",
        "interp.plot_confusion_matrix(normalize=True, figsize=(5,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNQxcK60jK5x"
      },
      "source": [
        "## Model ben√ºtzen\n",
        "\n",
        "Damit das Model auf dem Auto l√§uft, k√∂nnen wir es nicht wie schon gelernt mit `learn.save` abspeichern. (Du kannst `learn.save` trotzdem f√ºr das Training&Validierung n√ºtzen).\n",
        "\n",
        "Stattdessen speichern wir es im **ONNX-Format** (Open Neural Network Exchange). Dieser Format macht es einfach neuronale Netze auszutauschen und auf einem anderen Ger√§t laufen zu lassen:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRaX2qBEoCPs"
      },
      "source": [
        "### ONNX Speichern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RCIYbMOlJD8",
        "outputId": "26856548-c02e-409d-a0fe-7e15887fdc90"
      },
      "outputs": [],
      "source": [
        "# Wir m√ºssen zuerst ONNX installieren\n",
        "!pip install onnx --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "-QwJFYAP4fRD",
        "outputId": "147ad65a-6f7c-473b-8f03-f860a6ac747e"
      },
      "outputs": [],
      "source": [
        "# Check that no other transformers are present\n",
        "dls.after_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI6_Dzq6lZGt"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import onnx\n",
        "\n",
        "## Wir definieren, wo wir das ONNX speichern wollen\n",
        "onnx_export_filename = Path('/content/drive/MyDrive/AI-Challenge/models/stopsign_model.onnx')\n",
        "\n",
        "## ONNX √ºberschreibt die Datei falls sie schon existiert. Daher pr√ºfen wir hier ob das der Fall ist um nicht versehentlich etwas zu √ºberschreiben\n",
        "if onnx_export_filename.exists():\n",
        "  raise Exception(f\"onnx Modell {onnx_export_filename} existiert schon - l√∂sche es zuerst oder benenne es um, wenn du es behalten willst\")\n",
        "\n",
        "# Wir holen uns das Model aus dem Learner\n",
        "model = learn.model\n",
        "\n",
        "# Und versetzten es in den \"Eval\" Modus, damit ist es bereit f√ºr Vorhersagen\n",
        "model.eval()\n",
        "\n",
        "# Wir brauchen ein Beispiel-Bild um die Input-Shape f√ºr ONNX festzulegen.\n",
        "with Image.open(some_image_path) as img:\n",
        "    convert_tensor = transforms.ToTensor()\n",
        "    input_tensor_example = convert_tensor(img).unsqueeze(0)\n",
        "    # Hier k√∂nnen wir uns anschauen, wie die Shape aussieht. So weiss ONNX was es erwarten kann.\n",
        "    print(img.shape, input_tensor_example.shape)\n",
        "\n",
        "\n",
        "# Pr√ºfen, ob wir mit GPU lernen oder ohne, da der Input davon abh√§ngig ist\n",
        "if default_device().type == 'cuda':\n",
        "  input_tensor_example = input_tensor_example.cuda()\n",
        "\n",
        "# Model speichern\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    input_tensor_example,\n",
        "    onnx_export_filename,\n",
        "    input_names=[\"image\"],\n",
        "    output_names=[\"data\"]\n",
        ")\n",
        "\n",
        "print(f\"Model wurde als ONNX exportiert nach: {onnx_export_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2BW-0xT6m9q"
      },
      "outputs": [],
      "source": [
        "# Wir k√∂nnen mit diesen Zeilen pr√ºfen, ob es korrekt exportiert wurde und auch wieder importiert werden kann\n",
        "onnx_model = onnx.load(onnx_export_filename)\n",
        "onnx.checker.check_model(onnx_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDBiOAoalWaN"
      },
      "source": [
        "### ONNX laden und ben√ºtzten\n",
        "\n",
        "Wir schauen uns kurz an, wie man ein ONNX Modell laufen lassen kann. Das geschieht auch auf dem Auto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIM0i5TEjNYW",
        "outputId": "26613205-3a83-4544-8eee-ecc170856c56"
      },
      "outputs": [],
      "source": [
        "# Wir m√ºssen die ONNX-Runtime installieren\n",
        "! pip install onnxruntime~=1.15.1 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDsBtvg2Nvd1"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import onnxruntime as ort\n",
        "\n",
        "# Wir laden unser gespeichertes ONNX\n",
        "onnx_session = ort.InferenceSession(onnx_export_filename)\n",
        "\n",
        "# Und packen den Ablauf f√ºr Vorhersagen in eine Funktion\n",
        "def predict(image_path):\n",
        "    # Wir m√ºssen das Bild zuerst in das richtige Format bringen (das macht sonst FastAI f√ºr uns)\n",
        "    with Image.open(image_path) as img:\n",
        "        convert_tensor = transforms.ToTensor()\n",
        "        tensor_img = convert_tensor(img).unsqueeze(0).numpy()\n",
        "\n",
        "    # Hier starten wir die Vorhersage mit dem Bild als Input\n",
        "    pred = onnx_session.run(None, {'image': tensor_img})\n",
        "\n",
        "    return pred[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "lLz2tTWaRQiv",
        "outputId": "ee623b30-2b68-471d-b0de-5243bdaa8adf"
      },
      "outputs": [],
      "source": [
        "# Wir k√∂nnen nun eine Vorhersage mit einem Bild machen\n",
        "pred_percent = predict(some_image_path)\n",
        "\n",
        "# Und das Resultat anzeigen, je nachdem welche Prozentzahl h√∂her ist\n",
        "print(f\"Das Bild ist mit einer Wahrscheinlichkeit von {pred_percent:.0%}% ein Stoppschild\")\n",
        "\n",
        "\n",
        "# Zur Kontrolle, lassen wir uns das Bild noch anzeigen\n",
        "PILImage.create(some_image_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
